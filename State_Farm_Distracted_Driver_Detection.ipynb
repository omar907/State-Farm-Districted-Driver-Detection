{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "State Farm Distracted Driver Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omar907/State-Farm-Districted-Driver-Detection/blob/master/State_Farm_Distracted_Driver_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnnmo1QvGpj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install Tensorflow 2 to use this nootbook\n",
        "!pip install tensorflow==2.0.0-alpha0\n",
        "!pip install h5py pyyaml\n",
        "!pip install tf_nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKndJBOFqQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvROK4esccm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Upload the .json file of your kaggle account (you can generate it from the sittings of your kaggle account (API))\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEfVV3Apsx5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "\n",
        "#change the permission\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2P6k6RymZSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c state-farm-distracted-driver-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIiKZ22N0tqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Cell is responsible of creating a separate directory for on the cloud for our project\n",
        "\n",
        "# uncomment those lines in the very first time of using these nootbook\n",
        "#############\n",
        "!mkdir state_farm_distracted_driver_detection\n",
        "!mv imgs.zip state_farm_distracted_driver_detection\n",
        "!mv driver_imgs_list.csv.zip state_farm_distracted_driver_detection\n",
        "!mv sample_submission.csv.zip '/content/state_farm_distracted_driver_detection'\n",
        "#############\n",
        "\n",
        "\n",
        "%cd '/content/state_farm_distracted_driver_detection'\n",
        "#%cd Zipped_state_farm_distracted_driver_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Djh1-9q2iZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip Files\n",
        "from zipfile import ZipFile\n",
        "file_name1 = 'imgs.zip'\n",
        "file_name2 = 'driver_imgs_list.csv.zip'\n",
        "file_name3 = 'sample_submission.csv.zip'\n",
        "\n",
        "with ZipFile(file_name1,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done1')\n",
        "\n",
        "with ZipFile(file_name2,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done2')\n",
        "\n",
        "with ZipFile(file_name3,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnbYzxF37p0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Cell is just for organizing things\n",
        "# uncomment this cell in the very first time of using these nootbook\n",
        "################\n",
        "!mkdir Zipped_state_farm_distracted_driver_detection\n",
        "!mv imgs.zip Zipped_state_farm_distracted_driver_detection\n",
        "!mv driver_imgs_list.csv.zip Zipped_state_farm_distracted_driver_detection\n",
        "!mv sample_submission.csv.zip Zipped_state_farm_distracted_driver_detection\n",
        "################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pla4YsVHRUjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir validation\n",
        "%cd validation\n",
        "!mkdir c0 c1 c2 c3 c4 c5 c6 c7 c8 c9\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNp9IQg1rkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/state_farm_distracted_driver_detection'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directories with our training pictures\n",
        "train_dir_dictionry = {\n",
        "    'train_c0_dir' : os.path.join(train_dir,'c0'),\n",
        "    'train_c1_dir' : os.path.join(train_dir,'c1'),\n",
        "    'train_c2_dir' : os.path.join(train_dir,'c2'),\n",
        "    'train_c3_dir' : os.path.join(train_dir,'c3'),\n",
        "    'train_c4_dir' : os.path.join(train_dir,'c4'),\n",
        "    'train_c5_dir' : os.path.join(train_dir,'c5'),\n",
        "    'train_c6_dir' : os.path.join(train_dir,'c6'),\n",
        "    'train_c7_dir' : os.path.join(train_dir,'c7'),\n",
        "    'train_c8_dir' : os.path.join(train_dir,'c8'),\n",
        "    'train_c9_dir' : os.path.join(train_dir,'c9')\n",
        "}\n",
        "\n",
        " \n",
        "\n",
        "# Directory with our validation pictures\n",
        "validation_dir_dictionry = {\n",
        "    'validation_c0_dir' : os.path.join(validation_dir,'c0'),\n",
        "    'validation_c1_dir' : os.path.join(validation_dir,'c1'),\n",
        "    'validation_c2_dir' : os.path.join(validation_dir,'c2'),\n",
        "    'validation_c3_dir' : os.path.join(validation_dir,'c3'),\n",
        "    'validation_c4_dir' : os.path.join(validation_dir,'c4'),\n",
        "    'validation_c5_dir' : os.path.join(validation_dir,'c5'),\n",
        "    'validation_c6_dir' : os.path.join(validation_dir,'c6'),\n",
        "    'validation_c7_dir' : os.path.join(validation_dir,'c7'),\n",
        "    'validation_c8_dir' : os.path.join(validation_dir,'c8'),\n",
        "    'validation_c9_dir' : os.path.join(validation_dir,'c9')\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xj6aZbBeMnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_fnames = {\n",
        "    'train_c0_fnames' : os.listdir( train_dir_dictionry['train_c0_dir'] ),\n",
        "    'train_c1_fnames' : os.listdir( train_dir_dictionry['train_c1_dir'] ),\n",
        "    'train_c2_fnames' : os.listdir( train_dir_dictionry['train_c2_dir'] ),\n",
        "    'train_c3_fnames' : os.listdir( train_dir_dictionry['train_c3_dir'] ),\n",
        "    'train_c4_fnames' : os.listdir( train_dir_dictionry['train_c4_dir'] ),\n",
        "    'train_c5_fnames' : os.listdir( train_dir_dictionry['train_c5_dir'] ),\n",
        "    'train_c6_fnames' : os.listdir( train_dir_dictionry['train_c6_dir'] ),\n",
        "    'train_c7_fnames' : os.listdir( train_dir_dictionry['train_c7_dir'] ),\n",
        "    'train_c8_fnames' : os.listdir( train_dir_dictionry['train_c8_dir'] ),\n",
        "    'train_c9_fnames' : os.listdir( train_dir_dictionry['train_c9_dir'] )\n",
        "}\n",
        "\n",
        "# Just displaying some of the training images in the list\n",
        "for i in range(10):\n",
        "  #print(train_fnames['train_c'+str(i)+'_fnames'][:5])\n",
        "  print(len(train_fnames['train_c'+str(i)+'_fnames']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSpOf-OKTPwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### This section for validation\n",
        "validation_fnames = {\n",
        "    'validation_c0_fnames' : os.listdir( validation_dir_dictionry['validation_c0_dir'] ),\n",
        "    'validation_c1_fnames' : os.listdir( validation_dir_dictionry['validation_c1_dir'] ),\n",
        "    'validation_c2_fnames' : os.listdir( validation_dir_dictionry['validation_c2_dir'] ),\n",
        "    'validation_c3_fnames' : os.listdir( validation_dir_dictionry['validation_c3_dir'] ),\n",
        "    'validation_c4_fnames' : os.listdir( validation_dir_dictionry['validation_c4_dir'] ),\n",
        "    'validation_c5_fnames' : os.listdir( validation_dir_dictionry['validation_c5_dir'] ),\n",
        "    'validation_c6_fnames' : os.listdir( validation_dir_dictionry['validation_c6_dir'] ),\n",
        "    'validation_c7_fnames' : os.listdir( validation_dir_dictionry['validation_c7_dir'] ),\n",
        "    'validation_c8_fnames' : os.listdir( validation_dir_dictionry['validation_c8_dir'] ),\n",
        "    'validation_c9_fnames' : os.listdir( validation_dir_dictionry['validation_c9_dir'] )\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Just displaying some of the validation images in the list\n",
        "for i in range(10):\n",
        "  #print(validation_fnames['validation_c'+str(i)+'_fnames'][:5])\n",
        "  print(len(validation_fnames['validation_c'+str(i)+'_fnames']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9EF8Jm_Eny9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "\n",
        "## How much validation data do you want to sample\n",
        "data_val_percent = .2   # 20%\n",
        "\n",
        "\n",
        "# To move the images from the validation directories to the training directory if needed\n",
        "###########\n",
        "#for j in range(10):\n",
        "#  for i in validation_fnames['validation_c'+str(j)+'_fnames']:\n",
        "#    img_path=validation_dir_dictionry['validation_c'+str(j)+'_dir']+'/'+i\n",
        "#    shutil.move(img_path, train_dir_dictionry['train_c'+str(j)+'_dir'])\n",
        "###########\n",
        "\n",
        "\n",
        "## Randomly choose validation data \n",
        "for j in range(10):\n",
        "  x_history = []\n",
        "  Num_c_train_images = len(train_fnames['train_c'+str(j)+'_fnames'])\n",
        "  for i in range(int(Num_c_train_images*data_val_percent)):    #getting data_val_percent% of the traning data to be a validation data\n",
        "    x = np.random.randint(Num_c_train_images)\n",
        "    if (x in x_history):    # To be sure that x won't be repeated\n",
        "      continue\n",
        "    x_history.append(x)\n",
        "    img_path=train_dir_dictionry['train_c'+str(j)+'_dir']+'/'+train_fnames['train_c'+str(j)+'_fnames'][x]\n",
        "    shutil.move(img_path, validation_dir_dictionry['validation_c'+str(j)+'_dir'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql4yDAFEfyup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## printing the lengths of the training data\n",
        "for i in range(10):\n",
        "  print('total training c'+str(i)+' images :',len(train_fnames['train_c'+str(i)+'_fnames']))\n",
        "  \n",
        "\n",
        "print()  \n",
        "## printing the lengths of the validation data  \n",
        "for i in range(10):\n",
        "  print('total validation c'+str(i)+' images :',len(validation_fnames['validation_c'+str(i)+'_fnames'])) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lfernbAeM8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 1\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 100 # Index for iterating over images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHcE81QpeNGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_dir_dictionry['train_c'+str(j)+'_dir']\n",
        "#validation_dir_dictionry['validation_c'+str(j)+'_dir']\n",
        "#train_fnames['train_c'+str(j)+'_fnames']\n",
        "\n",
        "\n",
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "\n",
        "dict_pix = {} \n",
        "\n",
        "\n",
        "keys = []\n",
        "for i in range(10):\n",
        "  keys.append('next_c'+str(i)+'_pix')\n",
        "  \n",
        "\n",
        "for i in range(10):\n",
        "  values = []\n",
        "  values.append([os.path.join(train_dir_dictionry['train_c'+str(i)+'_dir'], fname) \n",
        "              for fname in train_fnames['train_c'+str(i)+'_fnames'][ pic_index-4:pic_index] \n",
        "             ])\n",
        "  dict_pix[keys[i]] = values\n",
        "           \n",
        "\n",
        "for j in dict_pix.keys():\n",
        "  for i, img_path in enumerate(dict_pix[j][0]):\n",
        "      # Set up subplot; subplot indices start at 1\n",
        "    sp = plt.subplot(nrows, ncols, i + 1)\n",
        "    sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw8-CedZ0Zkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yes627106f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(480, 480, 3)),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    #keras.layers.Dropout(0.2),     # Dropout layer for Overfitting\n",
        "    keras.layers.Dense(10, activation = 'softmax')    \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRIfefFJ11c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer= 'sgd',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "#print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LooQEL9qf0M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/state_farm_distracted_driver_detection\n",
        "#cwd = os.getcwd()  # Get the current working directory (cwd)\n",
        "#print(cwd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2VSZvYgUoTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255 #,\n",
        "    \n",
        "    # Data augmentation options that we find it unnecessary.\n",
        "#    rotation_range = 40,\n",
        "#    width_shift_range = 0.2,\n",
        "#    height_shift_range = 0.2,\n",
        "#    shear_range = 0.2,\n",
        "#    zoom_range = 0.2,\n",
        "#    horizontal_flip = True,\n",
        "#    fill_mode = 'nearest'\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(480, 480),  # All images will be resized to 640x480\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        validation_dir,  # This is the source directory for training images\n",
        "        target_size=(480, 480),  # All images will be resized to 640x480\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wd_KDGwMHvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 period = 1,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp1IpK2JRIEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recreate the exact same model, including weights and optimizer.\n",
        "#new_model = keras.models.load_model('my_model.h5')\n",
        "#new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkfEyWkO9S8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history = model.fit_generator( train_generator, steps_per_epoch=512,\n",
        "#epochs=1)\n",
        "\n",
        "# This line if I would use a validation data\n",
        "history = model.fit_generator( train_generator, steps_per_epoch=512, epochs=1,\n",
        "callbacks = [cp_callback], verbose=1, validation_data = validation_generator, validation_steps=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VAM0uK9KO7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "\n",
        "!pwd\n",
        "# Save entire model to a HDF5 file\n",
        "#model.save('my_model6.h5')\n",
        "\n",
        "# Save the weights\n",
        "#model.save_weights('my_checkpoint')\n",
        "\n",
        "#files.download('my_model6.h5')\n",
        "#files.download('my_checkpoint6.index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jREVkyjnp_DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9_ELkDOlQBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(640, 480))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  #print(classes[0])\n",
        "  \n",
        " # if classes[0]>0:\n",
        " #   print(fn + \" is a dog\")\n",
        " #   \n",
        " # else:\n",
        " #   print(fn + \" is a cat\")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0m8kUSCAwE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os, signal\n",
        "\n",
        "#os.kill(     os.getpid() , \n",
        "#         signal.SIGKILL\n",
        "#       )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}